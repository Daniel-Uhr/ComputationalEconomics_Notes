{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução aos Conceitos Básicos de Machine Learning\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "### Conteúdo\n",
    "\n",
    "* Introdução aos Conceitos Básicos de Machine Learning\n",
    "\n",
    "\n",
    "### Referências\n",
    "\n",
    "* Géron, Aurélien. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. O'Reilly Media, 2019.\n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introdução aos Conceitos Básicos de Machine Learning**\n",
    "\n",
    "### **1. Introdução ao Machine Learning**\n",
    "Machine Learning (ML) é uma subárea da inteligência artificial que utiliza algoritmos para identificar padrões em dados e realizar previsões ou classificações. Seu uso tem crescido exponencialmente em diversas áreas, incluindo economia, devido à capacidade de modelar relações complexas em grandes volumes de dados.\n",
    "\n",
    "#### **1.1. Definição Formal**\n",
    "ML pode ser definido como:\n",
    "> Um campo de estudo que dá aos computadores a capacidade de aprender sem serem explicitamente programados (Arthur Samuel, 1959).\n",
    "\n",
    "#### **1.2. Tipos de Problemas em ML**\n",
    "- **Supervisionado**: Há um conjunto de dados rotulados. Exemplos: Regressão e Classificação.\n",
    "- **Não Supervisionado**: Os dados não possuem rótulos. Exemplos: Agrupamento (Clustering) e Redução de Dimensionalidade.\n",
    "- **Semi-supervisionado**: Combinação de dados rotulados e não rotulados.\n",
    "- **Aprendizado por Reforço**: Envolve agentes que aprendem a realizar tarefas por tentativa e erro.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Métodos de Previsão e Classificação**\n",
    "\n",
    "#### **2.1. Modelos Supervisionados**\n",
    "\n",
    "##### **2.1.1. Regressão Linear e Logística**\n",
    "- **Regressão Linear**: Modelo paramétrico usado para prever variáveis contínuas.\n",
    "  - **Vantagens**: Simplicidade, interpretabilidade.\n",
    "  - **Desvantagens**: Assumem linearidade e não modelam interações não lineares.\n",
    "- **Regressão Logística**: Para classificação binária.\n",
    "  - **Vantagens**: Eficaz para classes balanceadas.\n",
    "  - **Desvantagens**: Dificuldade com dados desbalanceados.\n",
    "\n",
    "##### **2.1.2. Árvores de Decisão**\n",
    "- **Descrição**: Estruturas hierárquicas que particionam os dados em subconjuntos homogêneos.\n",
    "  - **Vantagens**: Intuitivas e não exigem pré-processamento extensivo.\n",
    "  - **Desvantagens**: Propensas ao overfitting.\n",
    "\n",
    "##### **2.1.3. Random Forest**\n",
    "- **Descrição**: Combinação de múltiplas árvores de decisão para melhorar a robustez.\n",
    "  - **Vantagens**: Redução do overfitting, eficiente para problemas não lineares.\n",
    "  - **Desvantagens**: Perde interpretabilidade.\n",
    "\n",
    "##### **2.1.4. Gradient Boosting (XGBoost, LightGBM)**\n",
    "- **Descrição**: Modelos baseados em árvores que otimizam iterativamente os erros residuais.\n",
    "  - **Vantagens**: Alta precisão em competições de ML.\n",
    "  - **Desvantagens**: Computacionalmente intensivo.\n",
    "\n",
    "##### **2.1.5. Support Vector Machines (SVM)**\n",
    "- **Descrição**: Algoritmos baseados em margens que utilizam funções de kernel para modelar dados complexos.\n",
    "  - **Vantagens**: Alta eficácia com classes complexas.\n",
    "  - **Desvantagens**: Não escala bem com grandes datasets.\n",
    "\n",
    "##### **2.1.6. Redes Neurais**\n",
    "- **Descrição**: Modelos inspirados no cérebro humano, eficientes para tarefas complexas e não lineares.\n",
    "  - **Vantagens**: Extremamente poderosas para dados não estruturados (imagens, texto).\n",
    "  - **Desvantagens**: Requerem grandes volumes de dados e alto poder computacional.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2. Modelos Não Supervisionados**\n",
    "\n",
    "##### **2.2.1. K-Means**\n",
    "- **Descrição**: Algoritmo de agrupamento que minimiza a variância intra-grupo.\n",
    "  - **Vantagens**: Simplicidade.\n",
    "  - **Desvantagens**: Sensível a outliers.\n",
    "\n",
    "##### **2.2.2. PCA (Principal Component Analysis)**\n",
    "- **Descrição**: Reduz a dimensionalidade dos dados mantendo a maior variância possível.\n",
    "  - **Vantagens**: Redução de dimensionalidade, identifica estruturas subjacentes.\n",
    "  - **Desvantagens**: Perda de interpretabilidade.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Conceitos Fundamentais Relacionados**\n",
    "\n",
    "#### **3.1. Validação Cruzada**\n",
    "- **Descrição**: Técnica de dividir os dados em partes de treinamento e teste para avaliar a robustez do modelo.\n",
    "  - **Tipos**:\n",
    "    - K-Fold Cross-Validation.\n",
    "    - Leave-One-Out Cross-Validation.\n",
    "  - **Importância**: Evita overfitting e underfitting.\n",
    "\n",
    "#### **3.2. Overfitting e Underfitting**\n",
    "- **Overfitting**: Modelo ajustado demais aos dados de treinamento.\n",
    "- **Underfitting**: Modelo não captura a complexidade dos dados.\n",
    "\n",
    "#### **3.3. Regularização**\n",
    "- **Técnicas**: LASSO, Ridge, Elastic Net.\n",
    "  - **Objetivo**: Penalizar coeficientes para evitar overfitting.\n",
    "\n",
    "#### **3.4. Feature Engineering**\n",
    "- **Descrição**: Processo de criar novas variáveis (features) para melhorar a capacidade preditiva.\n",
    "\n",
    "#### **3.5. Seleção de Modelos**\n",
    "- **Critérios**: R² ajustado, AUC, RMSE, etc.\n",
    "- **Trade-offs**: Complexidade x Interpretabilidade.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Considerações sobre Aplicação**\n",
    "\n",
    "#### **4.1. Quando usar cada modelo?**\n",
    "- **Regressão Linear/Logística**: Relações simples e interpretabilidade.\n",
    "- **Árvores de Decisão e Random Forest**: Dados complexos e interações não lineares.\n",
    "- **SVM**: Classes complexas e alta dimensionalidade.\n",
    "- **Redes Neurais**: Grandes datasets e dados não estruturados.\n",
    "\n",
    "#### **4.2. Vantagens e Desvantagens Gerais**\n",
    "- Modelos simples são mais interpretáveis, mas menos flexíveis.\n",
    "- Modelos complexos são mais precisos, mas requerem maior esforço computacional.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Exemplo Prático em Python**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados sintéticos\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n",
    "\n",
    "# Dividir dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar modelo\n",
    "scores = cross_val_score(model, X_test, y_test, cv=5)\n",
    "print(\"Acurácia média:\", scores.mean())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
