{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Regularization (Seleção de Modelos e Regularização)\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "### Conteúdo\n",
    "* Introdução\n",
    "* Cross-Validation (Validação Cruzada)\n",
    "  * The Validation Set Approach (A Abordagem do Conjunto de Validação)\n",
    "  * Leave-One-Out Cross-Validation (Validação Cruzada Leave-One-Out)\n",
    "  * k-Fold Cross-Validation (Validação Cruzada k-Fold)\n",
    "* The Bootstrap\n",
    "\n",
    "### Referências\n",
    "\n",
    "* [An Introduction to Statistical Learning](https://www.statlearning.com/) (ISL) by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani\n",
    "  * Capítulo 5***\n",
    "* [The Elements of Statistical Learning](https://hastie.su.domains/ElemStatLearn/) (ESL) by Trevor Hastie, Robert Tibshirani and Jerome Friedman : \n",
    "  * Capítulo 7\n",
    "\n",
    "***Disclaimer:*** *O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer feedback ou sugestão de melhoria.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceitos Fundamentais Relacionados\n",
    "\n",
    "\n",
    "#### **Validação Cruzada**\n",
    "\n",
    "**Descrição:**  \n",
    "A validação cruzada é uma técnica usada para avaliar a performance de um modelo dividindo os dados em partes de treinamento e teste, garantindo que o modelo seja avaliado de forma confiável e generalizável.\n",
    "\n",
    "**Tipos de Validação Cruzada:**\n",
    "- **K-Fold Cross-Validation:**  \n",
    "  Divide os dados em $K$ partes (folds). Em cada iteração, um fold é usado como teste e os outros $K-1$ como treinamento.\n",
    "  - **Vantagem:** Reduz a variância da avaliação do modelo.\n",
    "- **Leave-One-Out Cross-Validation (LOOCV):**  \n",
    "  Cada observação é usada como conjunto de teste uma vez, e todas as outras como treinamento.\n",
    "  - **Vantagem:** Usa quase todos os dados para treinamento.\n",
    "  - **Desvantagem:** Computacionalmente caro para grandes datasets.\n",
    "\n",
    "**Importância:**\n",
    "- Evita problemas de overfitting e underfitting.\n",
    "- Proporciona uma estimativa mais confiável da performance do modelo.\n",
    "\n",
    "\n",
    "#### **Overfitting e Underfitting**\n",
    "\n",
    "**Overfitting:**  \n",
    "Ocorre quando o modelo é excessivamente ajustado aos dados de treinamento, capturando ruídos e padrões específicos demais.  \n",
    "- **Sintomas:** Alta performance no treinamento, mas baixa performance em novos dados.  \n",
    "- **Exemplo:** Um modelo que ajusta exatamente cada ponto dos dados de treinamento.\n",
    "\n",
    "**Underfitting:**  \n",
    "Ocorre quando o modelo não consegue capturar a complexidade dos dados.  \n",
    "- **Sintomas:** Baixa performance tanto no treinamento quanto no teste.  \n",
    "- **Exemplo:** Um modelo linear usado para dados com uma relação não-linear.\n",
    "\n",
    "**Visualização:**\n",
    "- **Underfitting:** Modelo simples demais (reta em dados não-lineares).\n",
    "- **Good Fit:** Modelo adequado para os padrões gerais.\n",
    "- **Overfitting:** Modelo que segue cada ponto dos dados.\n",
    "\n",
    "\n",
    "#### **Regularização**\n",
    "\n",
    "**Descrição:**  \n",
    "Regularização adiciona penalidades aos coeficientes do modelo para evitar que eles assumam valores extremos, reduzindo o risco de overfitting.\n",
    "\n",
    "**Principais Técnicas:**\n",
    "- **LASSO (Least Absolute Shrinkage and Selection Operator):**  \n",
    "  Adiciona uma penalidade $\\lambda \\sum |\\beta_j|$, promovendo coeficientes esparsos (alguns $\\beta_j = 0$).\n",
    "- **Ridge Regression:**  \n",
    "  Adiciona uma penalidade $\\lambda \\sum \\beta_j^2$, encolhendo os coeficientes, mas não os eliminando.\n",
    "- **Elastic Net:**  \n",
    "  Combinação de LASSO e Ridge, com penalidade $\\lambda_1 \\sum |\\beta_j| + \\lambda_2 \\sum \\beta_j^2$.\n",
    "\n",
    "**Objetivo:**  \n",
    "Controlar a complexidade do modelo para melhorar sua generalização.\n",
    "\n",
    "\n",
    "#### **Feature Engineering**\n",
    "\n",
    "**Descrição:**  \n",
    "Feature engineering é o processo de criar, selecionar ou transformar variáveis (features) para melhorar a capacidade preditiva de um modelo.\n",
    "\n",
    "**Passos Importantes:**\n",
    "1. **Criação de Novas Features:**  \n",
    "   Combinar variáveis existentes ou criar interações (ex.: multiplicação, logaritmo, transformações).\n",
    "2. **Seleção de Features:**  \n",
    "   Escolher as variáveis mais relevantes para reduzir dimensionalidade.\n",
    "   - Técnicas comuns: Filtro, Wrapper, Embedded (ex.: LASSO).\n",
    "3. **Transformação de Features:**  \n",
    "   Padronizar ou normalizar variáveis numéricas para escalas uniformes.\n",
    "\n",
    "**Impacto:**  \n",
    "- Melhora a performance e interpretabilidade dos modelos.\n",
    "- Reduz o risco de overfitting ao evitar features redundantes.\n",
    "\n",
    "\n",
    "#### **Seleção de Modelos**\n",
    "\n",
    "**Descrição:**  \n",
    "Seleção de modelos é o processo de escolher o modelo que melhor equilibra performance e interpretabilidade.\n",
    "\n",
    "**Critérios de Avaliação:**\n",
    "- **$R^2$ Ajustado:** Para modelos de regressão.\n",
    "- **AUC (Área sob a Curva ROC):** Para modelos de classificação.\n",
    "- **RMSE (Root Mean Squared Error):** Para medir erros em predições contínuas.\n",
    "- **Log Loss:** Para avaliar probabilidades preditivas em classificação.\n",
    "\n",
    "**Trade-offs na Escolha:**\n",
    "- **Complexidade:** Modelos mais complexos geralmente têm maior capacidade preditiva, mas podem ser difíceis de interpretar.\n",
    "- **Interpretabilidade:** Modelos mais simples são mais fáceis de explicar, mas podem ter menor capacidade de capturar padrões complexos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Uso de ML em Economia\n",
    "\n",
    "Os problemas em economia frequentemente envolvem:\n",
    "\n",
    "* **Previsão de Séries Temporais:** Previsão de variáveis macroeconômicas, como inflação, PIB e taxas de desemprego.\n",
    "* **Análise de Impacto Causal:** Estimar o efeito de políticas públicas, como subsídios, impostos ou reformas.\n",
    "* **Classificação e Segmentação:** Identificar padrões em dados de consumidores, mercados ou empresas.\n",
    "* **Otimização de Decisões:** Melhorar políticas de alocação de recursos ou investimentos.\n",
    "\n",
    "Técnicas Mais Comuns\n",
    "\n",
    "* **Previsão:**\n",
    "  * Modelos de séries temporais: ARIMA, Prophet, Redes Neurais Recorrentes (RNN) e LSTMs.\n",
    "    * Algoritmos de regressão para prever preços, consumo, ou variáveis socioeconômicas.\n",
    "\n",
    "* **Causalidade e Inferência:**\n",
    "  * Double Machine Learning (DML), Modelos de Variáveis Instrumentais, Modelos Baseados em Controle Sintético.\n",
    "    * Exemplo: Avaliar o impacto de uma política fiscal sobre o PIB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações Finais\n",
    "\n",
    "Machine Learning é uma ferramenta poderosa para analisar dados complexos e extrair insights valiosos em economia. Com a crescente disponibilidade de dados e o desenvolvimento de algoritmos sofisticados, o uso de ML na economia está se tornando cada vez mais comum.\n",
    "\n",
    "O aprendizado supervisionado é predominante em economia. Isso ocorre por diversos fatores.\n",
    "* Natureza dos Dados em Economia: Muitos estudos econômicos trabalham com dados rotulados, o que é ideal para aprendizado supervisionado.\n",
    "* Foco em Predição e Causalidade: Economistas frequentemente estão interessados em prever uma variável dependente ou entender o impacto causal de uma política ou evento. Modelos supervisionados, como regressões, árvores de decisão, e redes neurais, são ferramentas diretas para esses objetivos.\n",
    "* Interpretação e Explicabilidade: Modelos como regressões lineares, árvores de decisão e random forests são supervisionados e mais interpretáveis, uma característica valorizada em economia.\n",
    "\n",
    "No entanto, técnicas de aprendizado não supervisionado, semi-supervisionado e por reforço também têm aplicações importantes em economia. Por exemplo, agrupamento de consumidores, redução de dimensionalidade em dados macroeconômicos e otimização de políticas públicas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
