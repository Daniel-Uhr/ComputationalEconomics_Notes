{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Bayesian Additive Regression Trees* (BART);\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "\n",
    "***Disclaimer:*** *O material apresentado aqui é uma adaptação do material de aula do Prof. Daniel de Abreu Pereira Uhr, e não deve ser utilizado para fins comerciais. O material é disponibilizado para fins educacionais e de pesquisa, e não deve ser reproduzido sem a devida autorização do autor. Este material pode conter erros e imprecisões. O autor não se responsabiliza por quaisquer danos ou prejuízos decorrentes do uso deste material. O uso deste material é de responsabilidade exclusiva do usuário. Caso você encontre erros ou imprecisões neste material, por favor, entre em contato com o autor para que possam ser corrigidos. O autor agradece qualquer feedback ou sugestão de melhoria.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução ao modelo *Bayesian Additive Regression Trees* (BART)\n",
    "\n",
    "**BART** é um modelo de aprendizado de máquina que combina duas ideias centrais:\n",
    "\n",
    "- A flexibilidade das árvores de regressão (*regression trees*) para capturar relações não lineares e interações entre variáveis;\n",
    "- A inferência **bayesiana**, que permite quantificar a ***incerteza das previsões*** e ***regularizar o modelo***.\n",
    "\n",
    "O BART ajusta uma **soma de várias árvores pequenas** (chamadas de *weak learners*), de forma semelhante ao Boosting — mas dentro de um **modelo bayesiano completo**.\n",
    "\n",
    "* Enquanto o Boosting reduz o viés a qualquer custo, o BART impõe uma regularização natural ao limitar a profundidade e o impacto de cada árvore via as priors. Isso ajuda a evitar overfitting de forma bayesiana.\n",
    "\n",
    "***Relembrando: o que é um modelo bayesiano?***\n",
    "\n",
    "> Em vez de buscar apenas um valor “ótimo” para os parâmetros (como nos modelos frequencistas), o modelo bayesiano calcula uma **distribuição de probabilidade** dos parâmetros, **dado os dados observados**.\n",
    "\n",
    "A intuição aqui é que **estamos mudando o papel das variáveis**: tratamos os dados $D$ como fixos, e os parâmetros $\\theta$ como variáveis aleatórias. Ou seja: **dado que observei os dados $D$, qual é a distribuição de probabilidade sobre os parâmetros $\\theta$?**\n",
    "\n",
    "A base para essa atualização de crença é o **Teorema de Bayes**:\n",
    "\n",
    "$$\n",
    "P(\\theta \\mid D) = \\frac{P(D \\mid \\theta) \\cdot P(\\theta)}{P(D)}\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $P(\\theta \\mid D)$: **posterior** – distribuição dos parâmetros após observar os dados;\n",
    "- $P(D \\mid \\theta)$: **verossimilhança** – quão compatíveis os dados $D$ são com o parâmetro $\\theta$;\n",
    "- $P(\\theta)$: **prior** – distribuição inicial sobre o parâmetro (antes de observar os dados);\n",
    "- $P(D)$: **função de normalização** – probabilidade marginal dos dados. Ela torna a posteriori uma distribuição válida e permite comparações entre modelos.\n",
    "\n",
    "> Ou seja: com métodos bayesianos, você começa com uma **crença inicial** (a priori) sobre os parâmetros.  \n",
    "> Ao observar os dados, você **atualiza** essa crença e obtém a **distribuição a posteriori**.  \n",
    "> As estimativas deixam de ser apenas um número (como um $\\hat{\\beta}$) e passam a ser **distribuições completas**, refletindo nossa incerteza.\n",
    "\n",
    "Na prática, aqui o pesquisador deve especificar:\n",
    "- Uma **verossimilhança** que descreve como os dados são gerados a partir desses parâmetros.\n",
    "  * Dados contínuos com erro normal\t$Y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
    "  * Dados binários (sucesso/fracasso)\t$Y_i \\sim \\text{Bernoulli}(p)$\n",
    "  * Contagens\t$Y_i \\sim \\text{Poisson}(\\lambda)$\n",
    "  * Tempo até evento\t$Y_i \\sim \\text{Exponencial}(\\lambda)$ ou $\\text{Weibull}$\n",
    "* Uma **distribuição a priori** para os parâmetros do modelo (o que acreditamos antes de ver os dados);\n",
    "\n",
    "***exemplo***\n",
    "* Modelo normal com média desconhecida: Suponha $Y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$ com $\\sigma^2$ conhecida.\n",
    "\n",
    "Podemos definir:\n",
    "* Verossimilhança:\n",
    "$P(y_i \\mid \\mu) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right)$\n",
    "* Prior (exemplo 1):\n",
    "$\\mu \\sim \\mathcal{N}(0, 10^2)$ → pouco informativa\n",
    "* Prior (exemplo 2):\n",
    "$\\mu \\sim \\mathcal{N}(5, 0.5^2)$ → se você tem conhecimento prévio do valor esperado\n",
    "\n",
    "\n",
    "***Como o Teorema de Bayes leva ao BART?***\n",
    "\n",
    "***Etapa 1: Problema de regressão***\n",
    "\n",
    "Queremos estimar uma função desconhecida $f(x)$ tal que:\n",
    "$$ y_i = f(x_i) + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2) $$\n",
    "\n",
    "O que BART vai fazer é modelar $f(x)$ como uma soma de várias árvores de decisão pequenas:\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{j=1}^{m} g(x; T_j, M_j)\n",
    "$$\n",
    "\n",
    "Então o modelo completo vira:\n",
    "\n",
    "$$\n",
    "y_i = \\sum_{j=1}^{m} g(x_i; T_j, M_j) + \\varepsilon_i, \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Os parâmetros desconhecidos são:\n",
    "* As estruturas das árvores $T_1, ..., T_m$\n",
    "* Os valores nas folhas $M_1, ..., M_m$\n",
    "* A variância do erro $\\sigma^2$\n",
    "\n",
    "A ideia bayesiana é: vamos colocar distribuições a priori sobre todos esses parâmetros, e depois aplicar o Teorema de Bayes.\n",
    "\n",
    "***Etapa 2: Priori + Verossimilhança = Posteriori***\n",
    "\n",
    "Com base no Teorema de Bayes:\n",
    "\n",
    "$$\n",
    "P(T_{1:m}, M_{1:m}, \\sigma^2 \\mid y, x) \\propto P(y \\mid x, T_{1:m}, M_{1:m}, \\sigma^2) \\cdot P(T_{1:m}, M_{1:m}, \\sigma^2) $$\n",
    "\n",
    "\n",
    "Aqui:\n",
    "* $P(y \\mid x, T_{1:m}, M_{1:m}, \\sigma^2)$, verossimilhança:\n",
    "Assume que $y_i \\sim \\mathcal{N}(f(x_i), \\sigma^2)$, com $f(x_i)$ vindo da soma das árvores.\n",
    "* $P(T_{1:m}, M_{1:m}, \\sigma^2)$, priori:\n",
    "São regras sobre como as árvores devem ser pequenas, rasas, com variância controlada.\n",
    "\n",
    "\n",
    "***Etapa 3: Como estimamos a posteriori?***\n",
    "\n",
    "A distribuição a posteriori de todas as árvores é muito complexa para calcular analiticamente.\n",
    "* Solução: amostramos da posteriori via MCMC (Markov Chain Monte Carlo)\n",
    "  * A cada passo do MCMC, mantemos todas as outras árvores fixas e atualizamos apenas uma árvore por vez ($T_j$, $M_j$), explorando o espaço das árvores de forma controlada.\n",
    "  * Atualiza essa árvore por meio de:\n",
    "  * Gibbs sampling: para os valores nas folhas $M_j$\n",
    "  * Metropolis-Hastings: para propor mudanças na estrutura $T_j$\n",
    "  * Repete isso ciclicamente para todas as árvores e $\\sigma^2$\n",
    "  * Depois de muitas iterações, temos amostras da posteriori do modelo completo.\n",
    "\n",
    "\n",
    "***Etapa 4: Como fazemos predições?***\n",
    "\n",
    "O MCMC gerou, digamos, S amostras da distribuição posterior.\n",
    "\n",
    "* Para cada iteração $s = 1, ..., S$, você tem um conjunto de árvores:\n",
    "* Estruturas das árvores: $T_1^{(s)}, T_2^{(s)}, ..., T_m^{(s)}$\n",
    "* Valores nas folhas: $M_1^{(s)}, M_2^{(s)}, ..., M_m^{(s)}$\n",
    "* Variância do erro: $\\sigma^{2(s)}$\n",
    "\n",
    "\n",
    "Dado um novo $x^*$, para cada iteração $s$ da cadeia de Markov, calculamos:\n",
    "\n",
    "$$\n",
    "\\hat{y}^*_s = \\sum_{j=1}^{m} g(x^*; T_j(s), M_j(s))\n",
    "$$\n",
    "\n",
    "Então, no final, teremos uma amostra de tamanho $S$ da distribuição preditiva de $y^*$:\n",
    "\n",
    "$$ \n",
    "\\hat{y}^* = \\left\\{ \\hat{y}^*_1, \\hat{y}^*_2, ..., \\hat{y}^*_S \\right\\}\n",
    "$$\n",
    "\n",
    "\n",
    "Previsão pontual (média Bayesiana):\n",
    "\n",
    "$$\n",
    "\\hat{y}^*_{\\text{média}} \\approx \\frac{1}{S} \\sum_{s=1}^{S} \\hat{y}^*_s\n",
    "$$\n",
    "\n",
    "Incerteza (Intervalo de Credibilidade):\n",
    "\n",
    "Exemplo de intervalo de 95%:\n",
    "* Limite inferior: 2,5º percentil da amostra ${ \\hat{y}^*_s }$\n",
    "* Limite superior: 97,5º percentil da amostra ${ \\hat{y}^*_s }$\n",
    "\n",
    "\n",
    "**Resumo da lógica do BART**\n",
    "\n",
    "| Etapa\t| O que é feito\t| Papel do Teorema de Bayes| \n",
    "|---\t|---\t|---\t|\n",
    "|1. Modelagem\t| $y = f(x) + \\varepsilon$, com $f(x)$ sendo soma de árvores pequenas\t| Define o objetivo da estimação\n",
    "|2. Priorização\t|Define priors sobre estruturas das árvores, folhas e $\\sigma^2$\t| Fornece regularização bayesiana |\n",
    "|3. Verossimilhança\t| $y_i \\sim \\mathcal{N}(f(x_i), \\sigma^2)$\t| Ligação entre os parâmetros e os dados |\n",
    "|4. Posteriori |\tUsa Bayes para obter distribuição sobre os parâmetros |\t$\\text{Posterior} \\propto \\text{Verossimilhança} \\cdot \\text{Prior}$ |\n",
    "|5. MCMC |\tGera amostras da posteriori via Gibbs + Metropolis\t| Estimativa numérica da posteriori |\n",
    "|6. Predição |\tMédia das amostras gera predição, quantis geram incerteza |\tIncerteza está incorporada nas amostras| \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
