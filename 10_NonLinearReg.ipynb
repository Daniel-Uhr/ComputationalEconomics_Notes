{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline\n",
    "\n",
    "Prof. Daniel de Abreu Pereira Uhr\n",
    "\n",
    "### Conteúdo\n",
    "\n",
    "\n",
    "### Referências\n",
    "\n",
    "* Géron, Aurélien. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. O'Reilly Media, 2019.\n",
    "* Athey, S., & Imbens, G. (2017). \"The State of Applied Econometrics: Causality and Policy Evaluation.\" *Journal of Economic Perspectives*.\n",
    "* Mullainathan, S., & Spiess, J. (2017). \"Machine Learning: An Applied Econometric Approach.\" *Journal of Economic Perspectives*.\n",
    "* Varian, H. R. (2014). \"Big Data: New Tricks for Econometrics.\" *Journal of Economic Perspectives*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard imports\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, BayesianRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Light GBM\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, warnings\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "   \n",
    "    https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html\n",
    "    \"\"\"\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "    \n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names_out'):\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [f for f in column]\n",
    "\n",
    "        return [f for f in trans.get_feature_names_out()]\n",
    "    \n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "    \n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == sklearn.pipeline.Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "    \n",
    "    \n",
    "    for name, trans, column, _ in l_transformers: \n",
    "        if type(trans) == sklearn.pipeline.Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names)==0:\n",
    "                _names = [f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_28140\\573609580.py:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "# Set inline graphs\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(df_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Testing data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(df_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.csv'"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(f\"Training data: {np.shape(df_train)} \\n Testing data: {np.shape(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução à Inteligência Artificial (AI) e Aprendizado de Máquina (ML)\n",
    "\n",
    "### Introdução à Inteligência Artificial (Atificial Intelligence - AI)\n",
    "\n",
    "Inteligência Artificial (AI) é um campo da ciência da computação que se concentra na criação de sistemas que podem executar tarefas que normalmente exigem inteligência humana. Essas tarefas incluem reconhecimento de fala, reconhecimento de imagem, tomada de decisão e tradução de idiomas. A IA é um campo amplo que abrange várias subáreas, como aprendizado de máquina, processamento de linguagem natural, visão computacional e robótica.\n",
    "\n",
    "Em outras palavras, pode ser definida como um campo amplo da ciência da computação que busca criar sistemas capazes de simular comportamentos humanos inteligentes, como aprendizado, raciocínio, resolução de problemas e tomada de decisões. Com **objetivo** de desenvolver máquinas que podem \"pensar\" ou resolver problemas de forma independente.\n",
    "\n",
    "**Escopo** da AI:\n",
    "\n",
    "* Machine Learning (ML): Aprendizado a partir de dados.\n",
    "* Planejamento: Tomada de decisões e estratégias.\n",
    "* Processamento de Linguagem Natural (NLP): Interação entre máquinas e linguagem humana.\n",
    "* Visão Computacional: Reconhecimento de imagens e vídeos.\n",
    "* Robótica: Interação física com o mundo.\n",
    "\n",
    "Vejamos as possíves subáreas da AI:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images\\IA_ML_DL.png\"  alt=\"Imagem\" style=\"width: 450px;\"/>\n",
    "</div>\n",
    "\n",
    "Assim, temos que:\n",
    "* AI: Campo amplo da ciência da computação que busca criar sistemas capazes de simular comportamentos humanos inteligentes.\n",
    "* ML: Subárea da AI que se concentra no desenvolvimento de algoritmos e modelos que permitem que os computadores aprendam a partir de dados.\n",
    "* DL: Subárea do ML que se concentra no desenvolvimento de redes neurais profundas para tarefas de aprendizado de máquina.\n",
    "\n",
    "A economia pode contribuir muito na área de ML. Então, vamos entender melhor o que é ML.\n",
    "\n",
    "### Introdução ao Aprendizado de Máquina (Machine Learning - ML)\n",
    "\n",
    "Aprendizado de Máquina (ML) é uma subárea da inteligência artificial que se concentra no desenvolvimento de algoritmos e modelos que permitem que os computadores aprendam a partir de dados. Em vez de serem explicitamente programados para executar uma tarefa, os modelos de aprendizado de máquina são treinados em um conjunto de dados para aprender padrões e fazer previsões ou tomar decisões.\n",
    "\n",
    "O **objetivo** do aprendizado de máquina é criar modelos que aprendem automaticamente a partir de dados, melhorando o desempenho com a experiência.\n",
    "\n",
    "**Escopo** do ML:\n",
    "* **Supervisionado:** Aprendizado a partir de dados rotulados. Regressão, classificação.\n",
    "* **Não supervisionado:** Agrupamento, redução de dimensionalidade.\n",
    "* **Aprendizado por reforço:** Agentes que aprendem por tentativa e erro\n",
    "\n",
    "\n",
    "### Relação entre AI-ML, ML-DL\n",
    "\n",
    "A inteligência artificial é um campo amplo que abrange várias subáreas, como aprendizado de máquina, processamento de linguagem natural, visão computacional e robótica. O aprendizado de máquina é uma subárea da inteligência artificial que se concentra no desenvolvimento de algoritmos e modelos que permitem que os computadores aprendam a partir de dados. Ou seja, ML é uma das técnicas utilizadas dentro da IA para alcançar comportamentos inteligentes. \n",
    "\n",
    "**Exemplo**:\n",
    "* AI: Desenvolver um sistema que possa jogar xadrez de maneira estratégica e vencer um grande mestre humano.\n",
    "* ML: Usar dados de jogos passados para treinar um modelo que preveja os melhores movimentos no xadrez.\n",
    "* DL: Usar redes neurais profundas para aprender padrões complexos no jogo de xadrez e melhorar a precisão das previsões.\n",
    "\n",
    "A IA pode usar ML como uma de suas ferramentas, mas também pode adotar outras técnicas não baseadas em aprendizado de dados. \n",
    "\n",
    "A relação ML e DL é que o DL é uma subárea do ML que se concentra no desenvolvimento de redes neurais profundas para tarefas de aprendizado de máquina. Redes neurais profundas são modelos de aprendizado de máquina que consistem em várias camadas de neurônios artificiais, permitindo que o modelo aprenda representações complexas dos dados. No DL o pesquisador perderá o controle sobre o modelo, mas ganhará em desempenho.\n",
    "\n",
    "### Importância do Aprendizado de Máquina na Economia\n",
    "\n",
    "**Motivação para o uso de ML na Economia**:\n",
    "\n",
    "* **Análise de Grandes Volumes de Dados (Big Data)**\n",
    "  * Com a crescente disponibilidade de dados econômicos de alta frequência e alta dimensionalidade (como transações financeiras, dados de redes sociais e registros administrativos), ML oferece ferramentas para analisar essas informações de maneira eficiente.\n",
    "  * Economistas podem usar ML para identificar padrões complexos que seriam difíceis de detectar com métodos tradicionais.\n",
    "* **Flexibilidade em Modelos Não Lineares**\n",
    "  * Muitas relações econômicas não seguem padrões lineares simples. ML permite modelar interações e não linearidades sem precisar especificá-las explicitamente.\n",
    "  * Exemplos: efeitos de políticas econômicas, preferências de consumidores, dinâmica de preços.\n",
    "* **Previsão**\n",
    "  * A previsão de séries temporais econômicas (PIB, inflação, preços de ativos) pode ser aprimorada com técnicas de ML como Redes Neurais e Gradient Boosting.\n",
    "  * Esses métodos frequentemente superam os modelos econométricos tradicionais, como ARIMA, em termos de precisão preditiva.\n",
    "* **Personalização e Segmentação**\n",
    "  * ML permite segmentar populações econômicas para personalização de políticas públicas ou estratégias de mercado.\n",
    "  * Exemplos: segmentar consumidores para políticas de subsídio, identificar regiões mais vulneráveis economicamente.\n",
    "* **Estimação Causal**\n",
    "  * Em áreas como economia do trabalho, ML auxilia na construção de variáveis instrumentais, balanceamento de covariáveis e estimação de efeitos heterogêneos.\n",
    "  * Métodos como Double Machine Learning (DML) são projetados para lidar com inferência causal em contextos de alta dimensionalidade.\n",
    "\n",
    "**Possíveis Aplicações do ML na Economia**\n",
    "* Mercado Financeiro\n",
    "  * Previsão de preços de ativos, gestão de portfólios e avaliação de risco utilizam extensivamente técnicas de ML.\n",
    "* Políticas Públicas\n",
    "  * ML é usado para identificar beneficiários elegíveis para programas sociais, avaliar políticas públicas e detectar fraudes.\n",
    "* Economia do Trabalho\n",
    "  * Analisar grandes bases de dados como RAIS e PNAD para prever salários, identificar padrões de emprego ou avaliar impacto de políticas trabalhistas.\n",
    "* Comércio Eletrônico\n",
    "  * Previsão de demanda, análise de comportamento do consumidor e precificação dinâmica.\n",
    "* Modelos de Preferências\n",
    "  * Análise de preferências reveladas e declaradas para entender escolhas de consumo e comportamento econômico.\n",
    "\n",
    "**Vantagens do Uso de ML na Economia**\n",
    "* Melhor desempenho preditivo: Os modelos de ML, quando bem ajustados, frequentemente superam os modelos econométricos tradicionais.\n",
    "* Automação de tarefas repetitivas: ML pode automatizar tarefas como imputação de dados, detecção de anomalias e análise exploratória.\n",
    "* Exploração de grandes conjuntos de dados: Ferramentas de ML conseguem trabalhar com alta dimensionalidade sem problemas significativos.\n",
    "* Capacidade de modelar relações complexas: Não linearidades, interações e efeitos heterogêneos podem ser modelados sem grande esforço.\n",
    "\n",
    "**Limitações do Uso de ML na Economia**\n",
    "* Falta de Interpretabilidade: Modelos de ML frequentemente sacrificam interpretabilidade em troca de desempenho preditivo.\n",
    "  * Muitos modelos de ML, como Redes Neurais, são frequentemente chamados de \"caixas-pretas\", dificultando a interpretação dos resultados.\n",
    "* Desafios em Inferência Causal\n",
    "  * Embora ML seja excelente para previsão, métodos tradicionais de econometria são frequentemente mais adequados para questões de inferência causal.\n",
    "  * Métodos híbridos, como Double Machine Learning (DML), tentam resolver esse problema.\n",
    "* Dependência de Grandes Volumes de Dados\n",
    "* Overfitting\n",
    "  * Se não gerenciado adequadamente, o treinamento do modelo pode levar a um ajuste excessivo aos dados, comprometendo a generalização.\n",
    "\n",
    "**Futuro do ML na Economia**\n",
    "\n",
    "Com o aumento da disponibilidade de dados e o desenvolvimento de métodos híbridos que combinam econometria e ML, espera-se que o uso de ML na economia cresça ainda mais. Técnicas como EconML, DoubleML e métodos de aprendizado profundo em séries temporais estão pavimentando o caminho para novas descobertas e aplicações econômicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução aos Conceitos Básicos de Machine Learning\n",
    "\n",
    "**Definição**\n",
    "\n",
    "Em termos gerais, ML pode ser definido como:\n",
    "\n",
    "> “[Machine Learning é o] ramo de estudos que dá aos computadores a habilidade de aprender sem terem sido explicitamente programados.” (Arthur Samuel, 1959).\n",
    "\n",
    "ou \n",
    "\n",
    "> “É dito que um programa de computador aprende de uma experiência E com respeito a alguma tarefa T e com alguma medida de performance P, se a performance em T, medida por P, melhora com a experiência E.” (Tom Mitchell, 1997).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de Problemas em Machine Learning\n",
    "\n",
    "O aprendizado de máquina pode ser classificado com base na **natureza do problema que os algoritmos tentam resolver**. Esses problemas são organizados em categorias principais: **aprendizado supervisionado, aprendizado não supervisionado, aprendizado semi-supervisionado e aprendizado por reforço**.\n",
    "\n",
    "#### 1. Aprendizado Supervisionado\n",
    "\n",
    "No aprendizado supervisionado, o algoritmo aprende a partir de um conjunto de dados de treinamento que contém **pares entrada-saída**, onde as saídas (rótulos - $Y$) estão disponíveis para cada exemplo de entrada.\n",
    "\n",
    "**Definição Formal:** Seja um conjunto de dados $D = \\{(x_i, y_i)\\}_{i=1}^n$, onde $x_i \\in \\mathbb{R}^d$ é o vetor de entrada e $y_i \\in \\mathbb{R}$ (regressão) ou $y_i \\in \\{1, 2, \\dots, k\\}$ (classificação) é a variável de saída. O objetivo é encontrar uma função $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ ou $f: \\mathbb{R}^d \\rightarrow \\{1, 2, \\dots, k\\}$, tal que minimize uma função de perda $\\mathcal{L}(y, f(x))$.\n",
    "\n",
    "A função de perda $\\mathcal{L}(y, \\hat{y})$ mede a diferença entre a saída predita $\\hat{y}=f(x)$ e o rótulo verdadeiro $y$. O objetivo é encontrar os parâmetros do modelo que minimizam a soma ou média das perdas em todo o conjunto de treinamento.\n",
    "\n",
    "Como exemplo de funções de perda, temos: \n",
    "- **Erro Quadrático Médio (Mean Squared Error - MSE):** Penaliza mais os erros grandes, pois eleva o erro ao quadrado.\n",
    "- **Erro Absoluto Médio (Mean Absolute Error - MAE):** Menos sensível a valores extremos (outliers).\n",
    "- **Huber Loss:** Combina MSE e MAE para lidar com outliers.\n",
    "- **Entropia Cruzada (Cross-Entropy):** Usada em problemas de classificação.\n",
    "- **Hinge Loss:** Utilizada em máquinas de vetores de suporte (SVMs) para classificação binária.\n",
    "\n",
    "A função de perda é crucial para guiar o processo de otimização e ajustar os parâmetros do modelo. \n",
    "\n",
    "**Exemplo prático:**\n",
    "Problema 1: Você deseja prever o preço de casas com base em características como número de quartos, área construída, localização e idade do imóvel.\n",
    "* Entradas (Features): Número de quartos, área construída, localização, idade.\n",
    "* Saída (Target): Preço do imóvel.\n",
    "* Algoritmos: Regressão Linear, Árvores de Decisão, Redes Neurais.\n",
    "  * Preparação dos dados (coletar, limpar, transformar variáveis).\n",
    "  * Treinar o modelo com os dados de treinamento, minimizando a função de perda.\n",
    "  * Avaliar o modelo com dados de teste (não vistos) para medir a performance.\n",
    "  * Fazer previsões com novos dados.\n",
    "\n",
    "Problema 2: Classificar e-mails como \"spam\" ou \"não spam\".\n",
    "* Entradas (Features): Palavras-chave, remetente, assunto, conteúdo.\n",
    "* Saída (Target): \"Spam\" (1) ou \"Não Spam\" (0).\n",
    "* Algoritmos: Regressão Logística, Naive Bayes, Random Forest.\n",
    "  * Pré-processar os dados (tokenização, remoção de stopwords, vetorização).\n",
    "  * Treinar o modelo com os dados de treinamento, minimizando a função de perda.\n",
    "  * Avaliar o modelo com dados de teste (não vistos) para medir a performance.\n",
    "  * Fazer previsões com novos e-mails.\n",
    "\n",
    "As técnicas de aprendizado supervisionado abrangem uma ampla gama de algoritmos, cada um com características e aplicações específicas. Eles podem ser categorizados com base no tipo de tarefa (regressão ou classificação), estrutura do modelo ou abordagem matemática.\n",
    "\n",
    "\n",
    "| **Categoria**                     | **Algoritmos**                                                                                                                                                     | **Intuição**                                                                                      |\n",
    "|-----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| **Regressão**                     | Regressão Linear Simples, Regressão Linear Múltipla, Regressão Logística, Regressão Ridge, Regressão Lasso, Elastic Net, Regressão Polinomial, Regressão Quantílica | Modelar relações entre variáveis explicativas (features) e uma variável dependente (target).    |\n",
    "| **Árvores de Decisão**            | Decision Tree, Random Forest, Gradient Boosting (GBM), XGBoost, LightGBM, CatBoost, Extra Trees                                                                  | Dividem os dados em subgrupos baseados em condições de decisão, formando estruturas em árvore.   |\n",
    "| **Máquinas de Vetores**           | Support Vector Machines (SVM) para Classificação, SVM para Regressão (SVR), Nu-SVM, Linear SVM                                                                  | Encontram um hiperplano ótimo que separa classes ou ajusta dados para regressão.                |\n",
    "| **Redes Neurais**                 | Multi-Layer Perceptron (MLP), Redes Neurais Convolucionais (CNN), Redes Neurais Recorrentes (RNN), Redes LSTM, Redes GRU, Redes Neurais Profundas (DNN)          | Simulam o comportamento de neurônios humanos para identificar padrões complexos em dados.       |\n",
    "| **Métodos Probabilísticos**       | Naive Bayes (Gaussian, Multinomial, Bernoulli), Hidden Markov Models (HMM), Maximum Entropy Classifier                                                          | Baseiam-se em probabilidade para classificar ou prever eventos.                                 |\n",
    "| **Métodos Ensemble**              | Bagging, Random Forest, Boosting (Adaboost, Gradient Boosting, XGBoost, LightGBM, CatBoost), Stacking, Blending                                                | Combinam múltiplos modelos para melhorar a precisão e robustez das previsões.                  |\n",
    "| **Métodos Baseados em Kernel**    | Regressão Kernel, SVM com Kernel (Linear, Polynomial, RBF, Sigmoid), Gaussian Processes                                                                         | Transformam os dados para um espaço dimensional superior para facilitar separações complexas.   |\n",
    "| **Métodos Bayesianos**            | Bayesian Linear Regression, Bayesian Logistic Regression, Gaussian Processes Regression (GPR)                                                                  | Incorporam inferências probabilísticas para lidar com incertezas nos modelos.                  |\n",
    "| **Métodos de Series Temporais**   | ARIMA, SARIMA, SARIMAX, Prophet, Regulação Espacial (Spatial Regression)                                                                                       | Lidam com dados sequenciais, considerando dependências temporais ou espaciais.                 |\n",
    "| **Métodos de Regularização**      | Regressão Lasso, Regressão Ridge, Elastic Net, Regressão Bayesiana Automática                                                                                   | Adicionam penalidades aos modelos para evitar overfitting e melhorar a generalização.          |\n",
    "| **Métodos de Distância**          | K-Nearest Neighbors (KNN), Classificação de Similaridade Coseno, Análise de Distância Mahalanobis                                                              | Avaliam proximidade ou similaridade entre pontos de dados com base em métricas de distância.    |\n",
    "| **Álgebras Tensoriais e Matrizes**| Factorização de Matrizes, Análise de Componentes Principais Supervisionada (SPCA)                                                                              | Reduzem dimensionalidade ou capturam relações latentes em dados de alta dimensão.              |\n",
    "| **Métodos Esparsos**              | Regressão Lasso, Regressão Bayesiana Esparsa                                                                                                                   | Identificam estruturas esparsas em dados, selecionando variáveis relevantes automaticamente.    |\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Aprendizado Não Supervisionado\n",
    "\n",
    "O aprendizado não supervisionado é um paradigma de Machine Learning no qual o modelo aprende padrões e estruturas a partir de dados não rotulados. Ao contrário do aprendizado supervisionado, onde as entradas (features) e saídas (rótulos) são fornecidas, no aprendizado não supervisionado, o modelo tenta descobrir relações, grupos ou representações subjacentes nos dados sem ter acesso a rótulos ou categorias pré-definidas.\n",
    "\n",
    "Objetivos do Aprendizado Não Supervisionado\n",
    "\n",
    "* Agrupamento (Clustering): Identificar subgrupos ou clusters de dados que compartilham características semelhantes.\n",
    "  * Exemplo: Dividir clientes em segmentos com base em comportamento de compra.\n",
    "* Redução de Dimensionalidade:Resumir ou compactar informações, mantendo o máximo possível de variabilidade dos dados.\n",
    "  * Exemplo: Compressão de dados ou visualização em 2D/3D.\n",
    "* Anomalias ou Outliers:Detectar padrões que não se ajustam bem ao comportamento esperado.\n",
    "  * Exemplo: Identificar transações fraudulentas em cartões de crédito.\n",
    "\n",
    "\n",
    "| **Categoria**              | **Algoritmos**                                                                                     | **Intuição**                                                                                      |\n",
    "|----------------------------|---------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| **Clustering (Agrupamento)** | K-Means, Hierarchical Clustering, DBSCAN, Mean-Shift, Gaussian Mixture Models (GMM), Spectral Clustering | Identifica grupos ou padrões ocultos em dados não rotulados, agrupando observações semelhantes.  |\n",
    "| **Redução de Dimensionalidade** | PCA (Principal Component Analysis), t-SNE, UMAP, ICA (Independent Component Analysis), Factor Analysis | Reduz a quantidade de variáveis (features) para simplificar dados, preservando sua estrutura.    |\n",
    "| **Modelagem de Densidade**   | Gaussian Mixture Models (GMM), Kernel Density Estimation (KDE), Mean-Shift                        | Estima a distribuição de probabilidade subjacente aos dados para identificar padrões.            |\n",
    "| **Análise de Associação**    | Apriori, FP-Growth                                                                               | Descobre regras e relações frequentes entre variáveis em conjuntos de dados (ex.: cestas de compras). |\n",
    "| **Modelos Baseados em Grafos**| Spectral Clustering, Community Detection, DeepWalk                                              | Analisam conexões e interações em dados estruturados como grafos, identificando comunidades ou padrões. |\n",
    "| **Métodos Baseados em Redes Neurais** | Autoencoders, Variational Autoencoders (VAE), Self-Organizing Maps (SOM)                          | Capturam estruturas latentes em dados para compressão, geração ou representação.                |\n",
    "| **Análise de Séries Temporais** | Dynamic Time Warping (DTW), Hidden Markov Models (HMM), Clusterização de Séries Temporais       | Identifica padrões em dados temporais sem informações rotuladas.                               |\n",
    "| **Métodos de Anomalias**      | Isolation Forest, One-Class SVM, Robust PCA                                                   | Detectam observações que se desviam significativamente do padrão geral dos dados.               |\n",
    "| **Modelagem de Tópicos**      | LDA (Latent Dirichlet Allocation), NMF (Non-Negative Matrix Factorization)                     | Descobre tópicos latentes em conjuntos de dados textuais.                                       |\n",
    "\n",
    "\n",
    "\n",
    "#### 3. Aprendizado Semi-Supervisionado\n",
    "\n",
    "O aprendizado semi-supervisionado combina características de aprendizado supervisionado e não supervisionado. Ele é especialmente útil quando temos uma grande quantidade de dados não rotulados, mas apenas uma pequena porção rotulada, devido ao custo ou dificuldade de rotular os dados.\n",
    "\n",
    "Objetivos do Aprendizado Semi-Supervisionado\n",
    "* Aproveitar os Dados Não Rotulados: Usar a informação contida nos dados não rotulados para complementar os dados rotulados, melhorando a capacidade do modelo.\n",
    "* Reduzir Custo de Rotulagem: Permitir que modelos sejam treinados de forma eficiente sem a necessidade de rotular todos os dados manualmente.\n",
    "* Explorar Estruturas Subjacentes: Identificar padrões ou relações nos dados não rotulados para guiar o aprendizado.\n",
    "\n",
    "Exemplo Prático:\n",
    "* Problema: Classificar e-mails como \"spam\" ou \"não spam\".\n",
    "* Dados disponíveis: 10% de e-mails rotulados como \"spam\" ou \"não spam\"; 90% não rotulados.\n",
    "* Solução: Um modelo semi-supervisionado usa os 10% rotulados para aprendizado inicial e aproveita padrões nos 90% não rotulados para refinar a classificação.\n",
    "\n",
    "\n",
    "| **Categoria**             | **Métodos e Algoritmos**                                                                                 | **Intuição**                                                                                       |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| **Self-Training**          | Self-Training, Pseudo-Labeling                                                                          | O modelo inicial é treinado com dados rotulados, e as previsões de alta confiança sobre dados não rotulados são usadas para expandir o conjunto rotulado. |\n",
    "| **Graph-Based Methods**    | Label Propagation, Label Spreading                                                                      | Usa grafos para modelar as relações entre dados rotulados e não rotulados, propagando rótulos através das conexões.                     |\n",
    "| **Co-Training**            | Co-Training                                                                                            | Treina dois modelos independentes em subconjuntos de features e permite que um modelo rotule os dados não rotulados para o outro.        |\n",
    "| **Semi-Supervised SVM**    | Semi-Supervised SVM                                                                                    | Expande o SVM tradicional, usando dados não rotulados para encontrar um limite de decisão que maximize a margem.                        |\n",
    "| **Generative Models**      | Semi-Supervised Variational Autoencoders (VAE), Generative Adversarial Networks (GANs)                 | Modelos generativos que aproveitam a estrutura latente dos dados para aprendizado semi-supervisionado.                                 |\n",
    "\n",
    "\n",
    "\n",
    "#### 4. Aprendizado por Reforço\n",
    "\n",
    "O aprendizado por reforço (Reinforcement Learning - RL) é um paradigma no qual um agente aprende a tomar decisões através da interação com um ambiente dinâmico. O objetivo do agente é maximizar uma função de recompensa acumulada ao longo do tempo.\n",
    "\n",
    "* Elementos do Aprendizado por Reforço\n",
    "  * **Agente:** Entidade que toma decisões e interage com o ambiente.\n",
    "  * **Ambiente:** O mundo no qual o agente opera e toma ações.\n",
    "  * **Estado (State - *s*):** Representação do ambiente em um determinado momento.\n",
    "  * **Ação (Action - *a*):** Decisão tomada pelo agente em um estado específico.\n",
    "  * **Recompensa (Reward - *r*):** Feedback imediato que o agente recebe após tomar uma ação.\n",
    "  * **Política (Policy - *π*):** Estratégia ou comportamento do agente para selecionar ações.\n",
    "  * **Valor (Value - *V*):** Medida de quão bom é um estado ou ação em um determinado momento.\n",
    "  * **Função de Q-Valor (Q-Value - *Q*):** Medida de quão bom é escolher uma ação em um determinado estado.\n",
    "\n",
    "Exemplo Prático\n",
    "* Problema: Treinar um robô para andar.\n",
    "* Estados: Posição do robô, inclinação, velocidade.\n",
    "* Ações: Mover pernas, ajustar direção.\n",
    "* Recompensa: Distância percorrida com sucesso sem cair.\n",
    "\n",
    "| **Categoria**             | **Métodos e Algoritmos**                                                                              | **Intuição**                                                                                       |\n",
    "|---------------------------|------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| **Baseado em Políticas**   | Policy Gradient, REINFORCE, Proximal Policy Optimization (PPO), Trust Region Policy Optimization (TRPO) | Aprende diretamente a política (\\(\\pi(a|s)\\)) para escolher ações, sem usar a função de valor.    |\n",
    "| **Baseado em Valores**     | Q-Learning, Deep Q-Networks (DQN), SARSA                                                             | Aprende a função \\(Q(s, a)\\) para estimar o valor de ações em estados específicos.                |\n",
    "| **Métodos de Ator-Crítico**| Advantage Actor-Critic (A2C), Asynchronous Actor-Critic (A3C), Soft Actor-Critic (SAC)               | Combina aprendizado de políticas e valores, onde o ator (policy) decide ações, e o crítico avalia.|\n",
    "| **Exploração Multiarmada** | Bandit Algorithms (Epsilon-Greedy, Upper Confidence Bound - UCB, Thompson Sampling)                  | Resolve problemas onde o agente precisa decidir entre várias opções sem dependência de estados.   |\n",
    "\n",
    "\n",
    "\n",
    "#### 5. Aprendizado por Transferência (Transfer Learning)\n",
    "\n",
    "O aprendizado por transferência é uma abordagem onde o conhecimento adquirido em uma tarefa (fonte) é reutilizado para resolver uma nova tarefa (alvo). Essa técnica é especialmente útil quando a tarefa alvo tem poucos dados disponíveis, mas está relacionada a uma tarefa para a qual há um modelo pré-treinado em um grande conjunto de dados.\n",
    "\n",
    "Aplicações\n",
    "* Visão Computacional: Usar redes pré-treinadas como ResNet, VGG ou EfficientNet em datasets como ImageNet e adaptá-las para tarefas específicas como classificação médica.\n",
    "* Processamento de Linguagem Natural: Modelos como BERT, GPT e T5 são treinados em grandes corpora e adaptados para tarefas específicas como análise de sentimentos ou tradução.\n",
    "* Reconhecimento de Voz: Modelos pré-treinados em grandes bases de dados de fala são adaptados para línguas ou sotaques específicos.\n",
    "\n",
    "\n",
    "| **Categoria**                   | **Métodos e Algoritmos**                                                                                 | **Intuição**                                                                                       |\n",
    "|---------------------------------|---------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| **Feature Extraction**          | Transferência de Camadas Congeladas                                                                      | Reutiliza as primeiras camadas de um modelo pré-treinado como extrator de features fixo.         |\n",
    "| **Fine-Tuning**                 | Fine-Tuning de Redes Neurais, Ajuste de Camadas Específicas                                              | Ajusta as camadas finais de um modelo pré-treinado para uma nova tarefa, mantendo outras fixas.  |\n",
    "| **Domain Adaptation**           | Adversarial Training for Domain Adaptation (ADDA), Maximum Mean Discrepancy (MMD)                        | Adapta um modelo para funcionar bem em um domínio diferente, reduzindo a discrepância entre domínios. |\n",
    "| **Zero-Shot Learning**          | CLIP (Contrastive Language–Image Pretraining), GPT                                                      | Usa um modelo pré-treinado em uma tarefa ampla para resolver uma nova tarefa sem treinamento adicional. |\n",
    "| **Few-Shot Learning**           | Prototypical Networks, Matching Networks, MAML (Model-Agnostic Meta-Learning)                           | Treina modelos para aprender rapidamente com poucos exemplos.                                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceitos Fundamentais Relacionados\n",
    "\n",
    "\n",
    "#### **Validação Cruzada**\n",
    "\n",
    "**Descrição:**  \n",
    "A validação cruzada é uma técnica usada para avaliar a performance de um modelo dividindo os dados em partes de treinamento e teste, garantindo que o modelo seja avaliado de forma confiável e generalizável.\n",
    "\n",
    "**Tipos de Validação Cruzada:**\n",
    "- **K-Fold Cross-Validation:**  \n",
    "  Divide os dados em $K$ partes (folds). Em cada iteração, um fold é usado como teste e os outros $K-1$ como treinamento.\n",
    "  - **Vantagem:** Reduz a variância da avaliação do modelo.\n",
    "- **Leave-One-Out Cross-Validation (LOOCV):**  \n",
    "  Cada observação é usada como conjunto de teste uma vez, e todas as outras como treinamento.\n",
    "  - **Vantagem:** Usa quase todos os dados para treinamento.\n",
    "  - **Desvantagem:** Computacionalmente caro para grandes datasets.\n",
    "\n",
    "**Importância:**\n",
    "- Evita problemas de overfitting e underfitting.\n",
    "- Proporciona uma estimativa mais confiável da performance do modelo.\n",
    "\n",
    "\n",
    "#### **Overfitting e Underfitting**\n",
    "\n",
    "**Overfitting:**  \n",
    "Ocorre quando o modelo é excessivamente ajustado aos dados de treinamento, capturando ruídos e padrões específicos demais.  \n",
    "- **Sintomas:** Alta performance no treinamento, mas baixa performance em novos dados.  \n",
    "- **Exemplo:** Um modelo que ajusta exatamente cada ponto dos dados de treinamento.\n",
    "\n",
    "**Underfitting:**  \n",
    "Ocorre quando o modelo não consegue capturar a complexidade dos dados.  \n",
    "- **Sintomas:** Baixa performance tanto no treinamento quanto no teste.  \n",
    "- **Exemplo:** Um modelo linear usado para dados com uma relação não-linear.\n",
    "\n",
    "**Visualização:**\n",
    "- **Underfitting:** Modelo simples demais (reta em dados não-lineares).\n",
    "- **Good Fit:** Modelo adequado para os padrões gerais.\n",
    "- **Overfitting:** Modelo que segue cada ponto dos dados.\n",
    "\n",
    "\n",
    "#### **Regularização**\n",
    "\n",
    "**Descrição:**  \n",
    "Regularização adiciona penalidades aos coeficientes do modelo para evitar que eles assumam valores extremos, reduzindo o risco de overfitting.\n",
    "\n",
    "**Principais Técnicas:**\n",
    "- **LASSO (Least Absolute Shrinkage and Selection Operator):**  \n",
    "  Adiciona uma penalidade $\\lambda \\sum |\\beta_j|$, promovendo coeficientes esparsos (alguns $\\beta_j = 0$).\n",
    "- **Ridge Regression:**  \n",
    "  Adiciona uma penalidade $\\lambda \\sum \\beta_j^2$, encolhendo os coeficientes, mas não os eliminando.\n",
    "- **Elastic Net:**  \n",
    "  Combinação de LASSO e Ridge, com penalidade $\\lambda_1 \\sum |\\beta_j| + \\lambda_2 \\sum \\beta_j^2$.\n",
    "\n",
    "**Objetivo:**  \n",
    "Controlar a complexidade do modelo para melhorar sua generalização.\n",
    "\n",
    "\n",
    "#### **Feature Engineering**\n",
    "\n",
    "**Descrição:**  \n",
    "Feature engineering é o processo de criar, selecionar ou transformar variáveis (features) para melhorar a capacidade preditiva de um modelo.\n",
    "\n",
    "**Passos Importantes:**\n",
    "1. **Criação de Novas Features:**  \n",
    "   Combinar variáveis existentes ou criar interações (ex.: multiplicação, logaritmo, transformações).\n",
    "2. **Seleção de Features:**  \n",
    "   Escolher as variáveis mais relevantes para reduzir dimensionalidade.\n",
    "   - Técnicas comuns: Filtro, Wrapper, Embedded (ex.: LASSO).\n",
    "3. **Transformação de Features:**  \n",
    "   Padronizar ou normalizar variáveis numéricas para escalas uniformes.\n",
    "\n",
    "**Impacto:**  \n",
    "- Melhora a performance e interpretabilidade dos modelos.\n",
    "- Reduz o risco de overfitting ao evitar features redundantes.\n",
    "\n",
    "\n",
    "#### **Seleção de Modelos**\n",
    "\n",
    "**Descrição:**  \n",
    "Seleção de modelos é o processo de escolher o modelo que melhor equilibra performance e interpretabilidade.\n",
    "\n",
    "**Critérios de Avaliação:**\n",
    "- **$R^2$ Ajustado:** Para modelos de regressão.\n",
    "- **AUC (Área sob a Curva ROC):** Para modelos de classificação.\n",
    "- **RMSE (Root Mean Squared Error):** Para medir erros em predições contínuas.\n",
    "- **Log Loss:** Para avaliar probabilidades preditivas em classificação.\n",
    "\n",
    "**Trade-offs na Escolha:**\n",
    "- **Complexidade:** Modelos mais complexos geralmente têm maior capacidade preditiva, mas podem ser difíceis de interpretar.\n",
    "- **Interpretabilidade:** Modelos mais simples são mais fáceis de explicar, mas podem ter menor capacidade de capturar padrões complexos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Uso de ML em Economia\n",
    "\n",
    "Os problemas em economia frequentemente envolvem:\n",
    "\n",
    "* **Previsão de Séries Temporais:** Previsão de variáveis macroeconômicas, como inflação, PIB e taxas de desemprego.\n",
    "* **Análise de Impacto Causal:** Estimar o efeito de políticas públicas, como subsídios, impostos ou reformas.\n",
    "* **Classificação e Segmentação:** Identificar padrões em dados de consumidores, mercados ou empresas.\n",
    "* **Otimização de Decisões:** Melhorar políticas de alocação de recursos ou investimentos.\n",
    "\n",
    "Técnicas Mais Comuns\n",
    "\n",
    "* **Previsão:**\n",
    "  * Modelos de séries temporais: ARIMA, Prophet, Redes Neurais Recorrentes (RNN) e LSTMs.\n",
    "    * Algoritmos de regressão para prever preços, consumo, ou variáveis socioeconômicas.\n",
    "\n",
    "* **Causalidade e Inferência:**\n",
    "  * Double Machine Learning (DML), Modelos de Variáveis Instrumentais, Modelos Baseados em Controle Sintético.\n",
    "    * Exemplo: Avaliar o impacto de uma política fiscal sobre o PIB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações Finais\n",
    "\n",
    "Machine Learning é uma ferramenta poderosa para analisar dados complexos e extrair insights valiosos em economia. Com a crescente disponibilidade de dados e o desenvolvimento de algoritmos sofisticados, o uso de ML na economia está se tornando cada vez mais comum.\n",
    "\n",
    "O aprendizado supervisionado é predominante em economia. Isso ocorre por diversos fatores.\n",
    "* Natureza dos Dados em Economia: Muitos estudos econômicos trabalham com dados rotulados, o que é ideal para aprendizado supervisionado.\n",
    "* Foco em Predição e Causalidade: Economistas frequentemente estão interessados em prever uma variável dependente ou entender o impacto causal de uma política ou evento. Modelos supervisionados, como regressões, árvores de decisão, e redes neurais, são ferramentas diretas para esses objetivos.\n",
    "* Interpretação e Explicabilidade: Modelos como regressões lineares, árvores de decisão e random forests são supervisionados e mais interpretáveis, uma característica valorizada em economia.\n",
    "\n",
    "No entanto, técnicas de aprendizado não supervisionado, semi-supervisionado e por reforço também têm aplicações importantes em economia. Por exemplo, agrupamento de consumidores, redução de dimensionalidade em dados macroeconômicos e otimização de políticas públicas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
